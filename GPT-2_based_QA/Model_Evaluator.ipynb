{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Evaluator",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nSlPL8e8Qp"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnEp5_K1UIxc"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU12il7BfBez"
      },
      "source": [
        "## Model initialization\n",
        "\n",
        "Getting the model weights from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGMlizuafNJd"
      },
      "source": [
        "Starting the session and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t92Q_nZfY8W"
      },
      "source": [
        "## Obtaining the results\n",
        "\n",
        "Splitting the validation set into question and answers sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmsg4TBwbuS7"
      },
      "source": [
        "val_questions = []\n",
        "val_answers = []\n",
        "\n",
        "for v in val:\n",
        "  val_questions.append(v.split('\\n')[0])\n",
        "  val_answers.append(v.split('\\n')[1])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQdvVJnafi27"
      },
      "source": [
        "Generating the answers to questions from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOfFkMypMqJ_"
      },
      "source": [
        "eval_answers = []\n",
        "for question in val_questions:\n",
        "  answer = gpt2.generate(sess,\n",
        "                length=300,\n",
        "                temperature=0.7,\n",
        "                top_k=40,\n",
        "                prefix=question,\n",
        "                nsamples=1,\n",
        "                batch_size=1,\n",
        "                )\n",
        "  eval_answers.append(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVCpjygEfoCj"
      },
      "source": [
        "Computing Precision, Recal, F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "num_c = []\n",
        "num_p = []\n",
        "num_g = []\n",
        "\n",
        "for a in range(len(eval_answers)):\n",
        "\n",
        "  common = collections.Counter(val_answers[a].split()) & collections.Counter(eval_answers[a].split()) # tokens shared between gold and predicted answers\n",
        "  num_common = sum(common.values())\n",
        "\n",
        "  num_pred = len(str(eval_answers[a]).split()) # the number of predicted tokens\n",
        "\n",
        "  num_gold = len(str(val_answers[a]).split()) # the number of gold tokens\n",
        "\n",
        "  num_c.append(num_common)\n",
        "  num_p.append(num_pred)\n",
        "  num_g.append(num_gold)\n",
        "\n",
        "precision = 1.0 * sum(num_c) / sum(num_p) # the num of tokens shared between gold and predicted answers / the num of predicted tokens\n",
        "recall = 1.0 * sum(num_c) / sum(num_g) # the num of tokens shared between gold and predicted answers / the num of gold tokens\n",
        "f1_score = (2 * precision * recall) / (precision + recall)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
