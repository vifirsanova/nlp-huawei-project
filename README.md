# A Russian Question Answering System for Inclusive Education

The dataset used for the model training: https://doi.org/10.6084/m9.figshare.13295831

The repository contains the code for the data preprocessing, model fine-tuning and evaluation of two transformers adapted for the question answering task: 
1. BERT based QA model
2. GPT-2 based QA model

The BERT based system implementation is based on Question Answering with SQuAD 2.0 guide: https://huggingface.co/transformers/custom_datasets.html?highlight=custom#qa-squad 

The GPT-2 based system implementation is based on by gpt-2-simple package by Max Woolf: https://minimaxir.com/2019/09/howto-gpt2/
